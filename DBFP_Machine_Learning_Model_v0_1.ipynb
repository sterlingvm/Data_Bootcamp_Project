{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBFP_Machine_Learning_Model_v0.1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# COVID-19 & Health Predictor \n",
        "\n",
        "##### - Data Bootcamp Final Project\n",
        "##### - Cordell, Gibbs, Miller, Ross"
      ],
      "metadata": {
        "id": "n0BawjXPWALv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qaez9x3gVrkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose: \n",
        "### Analyze COVID-19 Positivity or Negativity Based on Correlation to Nutrition"
      ],
      "metadata": {
        "id": "13nJrKwfWdyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pbLtuBdSWctT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gDWOUBdXXhQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: Random Forest Classifier"
      ],
      "metadata": {
        "id": "fEaTRIaOW8s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "v3RBpJM9WdDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library & Dependency Installation"
      ],
      "metadata": {
        "id": "WctJgqOdXBQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scikit-Learn Libraries/Dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "Z7EH209DXAFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Frame & Data Manipulation Libraries/Dependencies\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0En9AGs1XAfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data"
      ],
      "metadata": {
        "id": "TNb_ymioYq8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Physical Path Import"
      ],
      "metadata": {
        "id": "B5MelqPsavcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create File Path\n",
        "file_path = \"insert_file_path\"\n",
        "\n",
        "# Build the Dataframe\n",
        "dataframe = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "E1J3PcgpYqUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the Data\n",
        "dataframe.head(15)"
      ],
      "metadata": {
        "id": "Aim8nwEdYoFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Database"
      ],
      "metadata": {
        "id": "MMuAPwgua0Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mUy2CUAmkhv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Postgres Driver\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "metadata": {
        "id": "xpRKc-ADa4KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build Database Connection"
      ],
      "metadata": {
        "id": "m0iR3nMLdi-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Module to Communicate with PostgreSQL\n",
        "import psycopg2 as pg\n",
        "\n",
        "# Import Password Protector\n",
        "from getpass import getpass\n",
        "\n",
        "# Build Engine for Connection\n",
        "engine = pg.connect(\n",
        "    \"dbname='my_db_name' \n",
        "    user='pguser' \n",
        "    host='127.0.0.1' \n",
        "    port='15432' \n",
        "    password=getpass('pgpassword')\"\n",
        ")\n",
        "\n",
        "dataframe = pd.read_sql('select * from Stat_Table', con=engine)"
      ],
      "metadata": {
        "id": "BFJwsLQDlnnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Import Module to Communicate with PostgreSQL\n",
        "# import psycopg2\n",
        "\n",
        "# # Connection parameters - yours will be different\n",
        "# param_dic = {\n",
        "#     \"host\"      : \"localhost\",\n",
        "#     \"database\"  : \"globaldata\",\n",
        "#     \"user\"      : \"myuser\",\n",
        "#     \"password\"  : \"Passw0rd\"\n",
        "# }\n",
        "\n",
        "# # Define the connection function\n",
        "# def connect(params_dic):\n",
        "#     \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
        "#     conn = None\n",
        "#     try:\n",
        "#         # connect to the PostgreSQL server\n",
        "#         print('Connecting to the PostgreSQL database...')\n",
        "#         conn = psycopg2.connect(**params_dic)\n",
        "#     except (Exception, psycopg2.DatabaseError) as error:\n",
        "#         print(error)\n",
        "#         sys.exit(1) \n",
        "#     print(\"Connection successful\")\n",
        "#     return conn\n"
      ],
      "metadata": {
        "id": "4fy62w3ea4aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Connect to Database\n",
        "# connect(param_dic)"
      ],
      "metadata": {
        "id": "5SeMmlz1eqYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Retrieve Table/DataFrame from Database"
      ],
      "metadata": {
        "id": "h_u6scq8dlnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define our Data Table Retreival Function\n",
        "# def postgresql_to_dataframe(conn, select_query, column_names):\n",
        "#     \"\"\"\n",
        "#     Tranform a SELECT query into a pandas dataframe\n",
        "#     \"\"\"\n",
        "#     cursor = conn.cursor()\n",
        "#     try:\n",
        "#         cursor.execute(select_query)\n",
        "#     except (Exception, psycopg2.DatabaseError) as error:\n",
        "#         print(\"Error: %s\" % error)\n",
        "#         cursor.close()\n",
        "#         return 1\n",
        "    \n",
        "#     # Naturally we get a list of tupples\n",
        "#     tupples = cursor.fetchall()\n",
        "#     cursor.close()\n",
        "    \n",
        "#     # We just need to turn it into a pandas dataframe\n",
        "#     df = pd.DataFrame(tupples, columns=column_names)\n",
        "#               # *** Potentially change this ^ so that we don't have to input column names by hand ***\n",
        "#     return df"
      ],
      "metadata": {
        "id": "WkPK6X6Jda4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Retreive Data\n",
        "# postgresql_to_dataframe(conn, select_query, column_names)\n",
        "\n",
        "# # Rename DataFrame Variable\n",
        "# dataframe = df"
      ],
      "metadata": {
        "id": "2TGt-FvIe63s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process & Preprocess the Data"
      ],
      "metadata": {
        "id": "aWQrK58vaEfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Training & Test Splitting"
      ],
      "metadata": {
        "id": "3p13h1isguD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Separate Features from Outcomes"
      ],
      "metadata": {
        "id": "0Tr21vybhAyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Features(X)"
      ],
      "metadata": {
        "id": "ladDlXmYhWIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Features Dataset\n",
        "X = dataframe.copy()\n",
        "X = X.drop(\"insert_outcome_variable/column_name_here\", axis=1)\n",
        "\n",
        "# Preview the Dataset\n",
        "X.head(15)"
      ],
      "metadata": {
        "id": "AX9e213SaOEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Outcomes (y)"
      ],
      "metadata": {
        "id": "a28At8K2haKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Outcomes Dataset\n",
        "y = dataframe[\"insert_outcome_variable/column_name_here\"].values\n",
        "\n",
        "# Preview the data\n",
        "y.head(15)"
      ],
      "metadata": {
        "id": "U7nHMbYfaOMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Training & Testing Splits"
      ],
      "metadata": {
        "id": "Mb09NGwPiMkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data into Training & Testing (Default: 75%/25% Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=615, stratify=y, train_size=None)\n",
        "\n",
        "# | Change the split % by editting the \"train_size parameter to your training split percentage\" |\n",
        "      # Example: train_size = 0.80 results in an 80%/20% split"
      ],
      "metadata": {
        "id": "5fv4iIKIaOTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the shapes of the Split Datasets\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "Ufw80XLMio3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standardizing/Scaling the Data"
      ],
      "metadata": {
        "id": "eVDrBgP9jzxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Scaler\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "zo9piI1vj54G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit/Train Scaler to the Training Data\n",
        "X_scaler = scaler.fit(X_train)"
      ],
      "metadata": {
        "id": "DE3tWGt4j-Xf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}